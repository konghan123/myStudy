- 다중 컬럼 인덱스 설계
	- 다중컬럼 인덱스
		- = 복합인덱스
		- 테이블의 어러 컬럼을 조합해서 구성되는 인덱스
		- 복합인덱스는 ==명시된 컬럼 순서대로 정렬됨==
			- 설계 시 컬럼 순서에 따라서 쿼리 성능이 급격하게 차이남!!
			- (A,B)으로 인덱스를 구축하였을 때 A순서대로 정렬되고 이후 B순서대로 정렬되어 있음
			- 그러기에 A가 먼저 정렬되어 있기 때문에 B로 쿼리를 날릴 경우 인덱스를 타지 않고 풀스캔으로 쿼리돌림
		- 가장 왼쪽에 명시한 컬럼을 조건절로 넣지않으면 해당 인덱스를 타지 않는다.
	- 설계방법
		- 카디널리티가 높은 컬럼(유니크한 값이 많은 컬럼)을 선행컬럼으로 두기 좋다
		- 자주 사용되는 쿼리 중 특정 컬럼을 단독으로 사용하는 경우가 많다면 선행컬럼으로 두기 좋다
		- 인덱스를 사용하는 쿼리에서 조인을 자주 사용한다면 조인에 자주 사용되는 컬럼을 선행 컬럼으로 두기 좋다
		- 선행 컬럼이 범위 기반으로 쿼리를 사용한다면 선행 컬럼으로 두기 어렵다
	- 카디널리티 확인방법![[Pasted image 20240704212249.png]]
	- 복합 인덱스의 컬럼이 너무 많은 경우
		- 여러 컬럼을 조합해서 만든 hashed 컬럼을 인덱스로 만들어서 극복 가능![[Pasted image 20240704212411.png]]
- 커버링 인덱스를 통한 성능 최적화
	- 커버링 인덱스
		- 읽기 쿼리 성능을 높이기 위한 기법
		- 테이블 레코드에 접근하지 않고 인덱스 수준에서 쿼리를 처리하기 때문에 성능 향상됨
	- 언제 사용하는 것이 좋은가
		- 특정 컬럼 자주 조회
			- 특정 컬럼때문에 테이블에 접근하는 것이 비용이 크게 느껴질 때
		- 조인 연산 비용 줄이기
			- 여러테이블을 조인할때 비용을 줄임
		- 읽기 성능이 중요한 경우
			- 인덱스 레벨에서만 필터링을 하여 읽기 성능이 필요한 경우
	- 적용 고려 내용
		- 인덱스 컬럼 수
			- 인덱스가 커지면 인덱스 블록에 들어갈 수 있는 데이터 수가 줄어듬
			- 즉, 블록 크기가 커질수록 탐색하는 시간이 늘어남
		- 쓰기비용
		- 컬럼 크기
			- 큰 크기의 컬럼을 인덱스로 추가할 때 문제가 생김
		- 카디널리티
			- 카디널리티가 낮을 경우 성능 향상 미미
- ORDER BY 최적화
	- ORDER BY
		- ORDER BY 절에서 명시된 컬럼이 인덱스에 있으면 정렬된 데이터를 사용하므로 ==추가적인 정렬을 하지 않음==
		- 인덱스가 없는경우 filesort라는 방식으로 임시테이블을 사용해 정렬작업 수행
		- 정렬되어야하는 데이터가 적다면 메모리 수준에서 sortBuffer를 통해 정렬 진행
		- ==정렬되어야하는 데이터가 많다면 데이터를 쪼개 디스크에 저장 후 각각 정렬하고 합침==
		- 실행계획에서 Extra컬럼에 "Using filesort"가 있다면 filesort를 사용한것 
		- 실행계획에 key 컬럼에 인덱스가 출력되었다면 인덱스를 통해 정렬작업을 수행했다는 것
	- 최적화 방법
		- 인덱스를 이용한 최적화
			- ORDER BY 절을 사용하는 경우 인덱스를 사용하는 것이 좋음
			- LIMIT절과 함께 사용할 때 유의미
			- 인덱스가 없다면 테이블 전체 데이터를 정렬한 후 원하는 행 수만큼 추출
			- 인덱스가 있다면 MySQL은 필요한 만큼의 데이터만 읽고 처리 중단
		- filesort를 이용하는 경우 최적화
			- sort_bufffer_size 증가
				- 버퍼 크기를 증가시켜 디스크로 가는 정렬을 최소화
				- 추가적인 메모리 사용 부담이 적을 때 버퍼크기 증가
				- sort_merge_passes변수를 통해 디스크정렬을 수행했는지 파악 가능
				- 드라마틱한 성능개선은 아님
			- Single-Pass -> Two-Pass로 튜닝
				- filesort는 Single-Pass 와 Two-Pass 방식이 존재
				- Single-Pass
					-  Sort Buffer 에 정렬하는 데이터를 모두 넣어서 정렬을 수행
				- Two-Pass 
					- 1.정렬하는 칼럼과 PK 만 넣어서 정렬을 수행. 
					  1. 이후에 나머지 데이터와 병합.
					- 두단계를 통해 처리됨
				- 데이터가 너무 커서 소트 버퍼에 데이터를 조금 밖에 넣지 못한다면 그만큼 정렬작업이 느리기에 Two-pass방식이 더 빠를 수 있음
			- 문자열 정렬 튜닝
				- 문자열 컬럼은 값 전체를 사용하지 않고 max_sort_length만큼만 잘라서 정렬하면 버퍼에 들어갈 수 있는 값들이 많아져서 성능 향상
				- 단, 일부값으로 판단하여 정렬하기 때문에 정렬결과가 달라질 수 있음
			- 
- INSERT 최적화
	- INSERT 연결 비용 이해![[Pasted image 20240704221154.png]]
	- 최적화 방법
		- 대량삽입(Bulk Insert)
			- 여러번의 네트워크 통신을 줄이고 한 번에 많은 데이터를 전송
			- 방법
				- MULTIPLE VALUES 
					- 단일 INSERT 문에 VALUES 문을 여러개 두어 처리속도 개선
				- LOAD DATA 활용
					- LOAD DATA문을 통해 데이터가 들어있는 파일을 전달하여 대량의 데이터들을 삽입
					- LOAD DATA
						- 스토리지 엔진에서 지원하는 기능
						- INSERT문보다 20배 빠름
						- INSERT문과 달리 데이터가 들어있는 file을 줘야함
					- LOAD DATA 사용 주의점
						- AUTO_COMMIT은 사용하면 안됨
						- 병렬처리필요
							- 단일 스레드 + 단일 트랙잭션으로 처리
							- 즉, 처리되는 동안 Undo Log를 지울 수 없음
							- 여러파일로 나누어 병렬 처리가 필요할 수 있음
						- 데이터 파일을 전송하는 경우 보안 설정 필요![[Pasted image 20240704222117.png]]
					- LOAD DATA 사용 시 PK순으로 정렬하여 넣는 것이 성능이 좋음
		- 일관성 검사 지연
			- 삽입에 있어 일관성 검사를 미루어 속도 향상
			- 단. 일관성 검사가 필요한 경우 사용x
			- 
- innodb 락모드 설정을 통한 INSERT 최적화
	- innodb_autoinc_lock_mode 설정
		- Auto Increment 컬럼을 가진 테이블에 INSERT 작업시 동시성 수준 설정하는 기능
		- Simple insert : 기존 INSERT 문
			- 행수 예측 가능
		- Bulk insert :  INSERT... SELECT, LOAD DATA 등
			- 행수 예측 불가
		- 모드 종류
			- 0 : 모든 INSERT에 락 사용
			- 1 : Bulk는 락, Simple은 뮤텍스
			- 2 : 모두 뮤텍스
				- 단, 2를 사용 시 테이블락이 없기 때문에 자동 증가가 연속적으로 증가함을 보장하지 않음 (갭 발생 가능)
				- 즉, 마스터 서버의 데이터를 복제 서버가 데이터에 복제할 때 상태 기반이 아닌 row기반으로 복제해야함
			- ![[Pasted image 20240708202831.png]]
- 인덱스 다이브 최적화
	- 인덱스 다이브
		- MySQL이 실행 계획을 수립할 때 사용 가능한 인덱스를 평가하는 과정
			- 실제 인덱스 검색에 사용할 데이터를 가지고 스캔을 조금 해봄
			- 이 과정에서 수집된 정보를 바탕으로 사용할 인덱스를 결정
		- 효율적인 쿼리 실행을 위한 인덱스 선택에 중요한 역할
	- 옵티마이서 실행 계획 수립 우선순위
		- 1. 인덱스 다이브을 이용한 예측
		- 2. 히스토그램을 이용한 예측
		- 3. 인덱스 통계를 이용한 예측
	- 인덱스 다이브 비용
		- IN 절의 LIST가 많은 경우
		- IN절, OR절을 같이 여러개 쓰는 경우
		- 범위 조건이 많은 경우
	- 인덱스 다이브가 나쁜게 아님
	- 인덱스 다이브 비용이 높은 경우
		- FORCE INDEX를 이용하여 인덱스 강제
		- eq_range_index_dive_limit 변수를 조정
			- 변수로 지정한 값보다 많은 비교를 해야한다면 Index Dive 는 하지 않고 인덱스 통계 정보만을 가지고 실행 계획을 수립 
			- 단, 비교는 동등비교일때 해당됨
- Prefix Index 최적화
	- Prefix Index
		- 컬럼의 전체 값 대신 일부 접두사만을 이용하여 인덱스 구축
		- BLOB, TEXT, 긴 VARCHAR의 경우 전체 인덱싱이 불가능하기에 Prefix Index를 사용해야함
	- 최적화 방법
		- 카디널리티가 충분히 높아지는 접두사 길이를 선택
			- SELECT문을 통해 길이를 하나씩 늘리면서 중복되는 값의 변화가 적어지는 시점부터 Prefix Index를 잡음
- InnoDB 데드락 감지 최적화
	- 데드락 감지
		- LOCK을 요구하는 연산은 데드락 감지 스레드를 통해 데드락을 유발하는지 주기적으로 검사함
		- 많은 LOCK을 요구하는 서비스라면 데드락 감지 스레드 때문에 지연 발생
		- 방식
			- 데드락 감지 스레드가 검사하는 동안에는 LOCK을 가진 서비스들은 LOCK을 반납하지 못함
	- 최적화 방법
		- 데드락 감지 기능을 꺼버림
			- 단, 감지 기능을 끄면 데드락 감지를 못하기 때문에 innodb_lock_wait_timeout값을 적절하게 설정해야함 (기본은 50초)
		- 락을 기다리는 트랙잭션을 시스템이 파악하여 해당 감지 기능을 꺼버리는 방식으로 진행![[Pasted image 20240708211618.png]]
- LIMIT 절 Offset 최적화
	- LIMIT 절 Offset을 사용하는 것을 지양해야함
		- offset을 사용하면 지정된 수만큼의 데이터를 읽고 버려야하기 때문
		- 10번째까지 제외하고 그다음부터 100000개만 출력![[Pasted image 20240708212043.png]]
- SELECT..FOR UPDATE의 SKIP LOCKED 최적화
	- SELECT FOR UDPATE
		- 조회하는 레코드에 잠금을 거는 기능, 다른 트랜잭션이 해당 레코드에 쓰거나 변경할 수 없음
	- SKIP LOCKED
		- 잠금이 걸린 레코드를 건너뛰고 잠금이 없는 레코드만 조회하고 잠금
	- 최적화 방법
		- SKIP LOCKED을 활성화
		- 동시성이 높은 환경에서 성능 최적화(선착순 쿠폰 배포 시스템 등)
		- 잠금 대기시간 감소 및 처리량 증가
		- 엄청난 최적화 가능
- InnoDB 버퍼풀 최적화
	- 버퍼풀
		- 테이블 데이터와 인덱스 데이터를 메모리에 캐싱하고 변경된 데이터를 디스크에 플러시하는 역할
		- 버퍼풀은 인스턴스로 나눠짐
			- 인스턴스 단위로 Flush List(플러시될 데이터를 모아놓은 리스트)와 LRU리스트(테이블 데이터, 인덱스 데이터가 캐싱되어 있는 리스트)로 나뉨
		- 인스턴스를 늘리면 동시성 수준 성능 증가
	- 최적화 방법
		- innodb_buffer_pool_size 조절
			- OS 메모리의 70~80%정도 할당
			- 메모리 크기가 8 GB라면 OS메모리의 50%
		- nnodb_buffer_pool_instance 수 조절
			- innodb_buffer_pool_size에 맞게 innodb_buffer_pool_instance 수도 조절
			- 메모리가 40GB밑이라면 기본값 사용
			- 메모리가 40GB위라면 5GB마다 1씩 증가
- InnoDB 버퍼풀 플러싱 최적화
	- 플러싱
		- 버퍼 풀에 쌓인 변경된 데이터를 디시크에 주기적으로 플러시하는 과정
	- 플러싱 메커니즘
		- Page Cleander Thread가 해당 변경된 데이터를 플러쉬하는 역할을 담당
	- 최적화 방법
		- Page Cleander Thread 수 증가(기본값은 4)
			- 최대값은 버퍼 인스턴스 수와 같음
		- 플러싱 인접 페이지 설정 값을 조절하여 이웃 페이지와 함께 플러쉬하는 방식
			- innodb_flush_neighbors
				- 0이면 이웃 페이지들과 플러쉬하지 않음
				- 1이면 연속된 변경된 페이지들은 같이 플러쉬
				- 2이면 같은 extent에 있는 더티페이지까지 같이 플러쉬
	- 
- Redo log / log file size 최적화
- Redo log
	- 데이터 변경 내역을 로그에 저장하는 방식
	- 즉, 커밋햇지만 아직 디스크에 반영도지ㅣ 않은 데이터가 있는 상황에서 MySQL이 죽은 경우 복구할 때 사용
	- inno_flush_log_at_trx_commit 값에 따라 플러쉬 시점이 달라짐
		- 값이 0이면 1초에 한번씩 플러쉬
		- 값이 1이면 매 트랜잭션마다 디스크에 플러쉬
		- 값이 2이면 매 트랜잭션마다 커밋되면 운영체제의 메모리 버퍼에 기록되고 동기화는 1초마다 유지 (운영체제가 정상작동한다면 데이터 보장)
	- 트랜잭션 처리와 Redo Log 기록 과정
		- 1. 트랜잭션이 데이터를 변경하면 해당 변경내용이 먼저 Log Buffer에 기록됨
		- 2. 트랜잭션이 커밋을 요청하면 MySQl은 먼저 LOG Buffer에 있는 모든 관련 로그 기록을 Redo Log 파일로 플러쉬
		- 3. Log Buffer 내용이 Redo Log 파일로 플러시된 후 트랜잭션이 성공하면 커밋됨. 이로써 데이터 변경 사항이 안정적으로 저장된 것으로 간주함
- 체크포인트
	- 데이터베이스가 Redo Log 내용을 정기적으로 디스크 실제 데이터 파일로 플러시 하는 과정
- 최적화 방법
	- Redo Log 파일 사이즈 증가
		- 파일 사이즈만큼 가득차게 되면 Redo Log의 변경된 데이터 내역들이 디스크 데이터에 반영되어야하는 체크포인트가 발생하면서 비용 생김
		- 해당 사이즈가 작다면 자주 disk Write가 발생
		- 적절한 사이즈 측정을 위해선 피크 트래픽동안의 Redo Log 파일이 쌓이는 사이즈를 측정하여 이를 바탕으로 설정
	- Log Buffer 사이즈 증가
		- 트랜잭션 변경 내용은 Log Buffer에 쌓이게 되고 가득차면 그때마다 Redo Log 파일로 플러쉬하는 과정이 발생하고 결국 디스크 플러시까지 일어나 느려짐
		- innodb_log_waits 상태 변수를 통해 한 트랜잭션에서 이 값이 올랏다면 버퍼크기를 늘려줌