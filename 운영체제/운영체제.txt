운영체제 > 하드웨이를 효율적으로 관리해서 사용자에게 서비스를 제공 (운영체제는 프로세서에게 처리할 작업을 할당 및 관리)
하드웨어>> 프로세서(계산하는 녀석 ex. cpu 그래픽카드 응용전용처리장치) 메모리(저장하는 녀석 ex. D-ram disk)  주변장치(키보드 마우스 모니터 프린터)가 존재
프로세서 > 컴퓨터의 두뇌 >연산 수행 , 장치의 동작 제어
프로세서 > 레지스터, 연산장치, 제어장치
레지스터 > 프로세서 내부에 있는 저장하는 메모리, 가장 빠른 메모리 / 
사용자 가시 레지스터 / 사용자 불가시 레지스터 ( 프로그램 카운터 , 명령어 레지스터 , 누산기) 
메모리 > 레지스터 ,캐시, 메인 메모리 , 보조기억장치 / 처음 순부터 속도가 빨라지고 가격은 올락가면서 용량은 작아짐 (적당히 서로 이용하여 최고의 효율을 내자)
주기억장치 > dram(ddr)를 주로 사용, 디스크 입출력 병목현상을 해소시켜줌. cpu속도와 disk 속도의 갭차이 때문에 주기억장치를 통해 그 갭을 해소. 프로세서<>주기억장치<>디스크
캐시> 메인 메모리의 입출력 병목현상을 해소 (이것도 갭차이를 메꾸는데 사용) 프로세서 <> 캐시 <> 주 기억장치
캐시가 효과가 나는 이유 > 지역성 >참조한 주소와 인접한 주소를 참조하며 한번 참조한 주소를 곧 다시 참조하는 특성때문
보조기억장치 > 데이터 저장. 프로세서가 직접 접근은 불가(주 기억장치를 거쳐서 접근)
시스템 버스 > 프로세서 메인 메모리 주변장치들이 데이터를 주고 받는 통로(제어버스, 주소버스, 데이터버스 가 있다)

운영체제의 역할 > 편리성[인터페이스](cui문자,gui그림), 효율성(하드웨어 소프트웨어 관리), 프로세스,스레드 관리, 시스템 보호 
시스템 콜(시스템 라이브러리)을 통해 사용자가 원하는 것을 파악하여 커널에서 필요한 기능을 요청한다. (요청통로) [그림1 참조]

운영체제 구조 > 커널(os의 핵심부분:프로세스관리,메모리관리)과 유틸리티(커널의 제외한 나머지:ui,비상주프로그램) 
계층구조 운영체제 구조(최근 운영체제) > 모듈화 계층간 나눔! 관리 쉬움 , 하지만 성능 안좋음
단일 구조 운영체제 구조 > 커널 거대화, 성능좋음 하지만 관리힘듬
마이크로 커널 구조 > 커널 필수기능만 담아 최소화 기타 기능은 사용자 영역에서 수행

운영체제는 다양한 리소스를 "관리"
프로세스란? 커널에 등록된 실행 단위, 커널의 관리하에 있는 작업이다. 수행의 주체가 된다.
운영체제는 프로세스간 교착상태도 해소한다.
프로세서란? cpu라고 봐도 된다. >> 프로세스들을 할당, 처리순서 결정 (운영체제는 프로세서도 관리)
파일이란? 논리적 데이터 저장 단위 (운영체제는 파일도 관리) 
반드시 운영체제를 거쳐서 입출력관리가 가능하다

잡/프로그램> 실행할 프로그램 + 데이터
프로세스> 프로그램 실행을 위해 커널에 등록된 작업(시스템 성능향상을 위해 커널에서 관리됨)
자원이란? 커널의 관리하에 프로세스에게 할당/반납되는 수동적 개체
프로세스 컨트롤 블럭(pcb)> 프로세스를 컨트롤하기 위해 필요한 정보를 저장한 공간(커널이 가지고 잇슴)/ pcb에 따라 os성능을 결정짓는 요소중 하나
프로세스 상태
생성상태(작업을 커널에 등록 pcb 할당및 프로세스 생성):메모리 유무에 따라 ready or suspend ready
레디상태(프로세서 외 모든 자원을 할당 받은 상태, 프로세서 할당 대기상태, 즉시 실행 가능상태)
러닝상태(프로세서와 필요한 자원을 모두 할당 받은 상태) / preemption(프로세서를 뺏김): 러닝 > 레디 / block sleep(i/o를 가지러 간상태) : 러닝 > 슬립 > 레디 > 러닝 반복
터미네이디트(프로세스 수행이 끝난상태, 자원 반납 후 커널 내 일부 pcb정보만 남아 있는 상태) 

인터럽트 > 예상치 못한, 외부에서 발생한 이벤트  
인터럽트 발생하면 프로세스를 중단하고 인터럽트를 처리한다 그리고 인터럽트 핸드링( 원인,장소 파악 > 어떻게 처리할건지 파악)이후 인터럽트 서비스 호출.
context switching
context >프로세스와 관련된 정보들의 집합
context saving > 현재  프로세스의 register context를 저장한느 작업 (메모리 안의 pcb에 저장이 됨)
context restoring > register context를 프로세스로 복구
context switching > 실행 중인 프로세스의 context를 저장하고 앞으로 실행 할 프로세스의 context를 복구하는 일 (pi(하고 있던일)>pj(다음할일)로 바뀜)(커널의 개입으로 바뀜)
context switching는 자주 일어나는 일이여서 os성능에 큰영향을 줌 그리고 이것을 줄이는 것이 중요!!(스레드를 사용하여 줄일 수 있다.)

스레드>프로세스에서 자원들을 제어하는 것 (한 프로세스 안에 여러가지 스레드가 있을 수 잇슴 하지만 리소스(힙,데이터,코드)는 공유됨!!!)
스레드안에는 제어정보(프로그램카운터,상태,스택포인터), 지역데이터(한정된 부분에서만 유효한 데이터), 스택(작업영역)이 있다.
스레드> 가벼운 무게의 프로세스이며 프로세서 활용의 기본단위이다. 제어요소 외 자원들은 프로세스 내 스레드들과 공유!! 즉, 자원을 공유하며 각각의 제어요소가지고 잇는 것!
스레드 장점> 일부 스레드의 처리가 지연되어도 다른 스레드는 작업을 계속 처리(멀티가 가능), 자원을 공유해서 효율성 증가(커널의 개입을 피할 수있다), context switch에 비해 효율적, 병렬처리를 통해 성능향상
사용자 수준 스레드(다대일 매핑)는 커늘은 모르기 때문에 유연한 관리가 가능하고 부하가 적으며 이식성도 높다. 그래서 커널은 프로세스 단위로 할당하기 대문에 한개의 스레드가 꺼지면 나머지도 대기해야함
커널 수준 스레드(일대일 매핑)는 커널이 직접 관리하기 때문에 부하가 크다. 그래서 한개의 스레드가 꺼져도 나머지 스레드는 대기하지 않는다.
혼합형 스레드(다대다 매핑)는 두 수준을 혼합형이며 사용자 수준 스레드의 수가 더 많거나 같으며 효율적!

프로세스 스케줄링 하는 이유: 여러개의 프로세스가 시스템 내 존재하며 자원을 할당할 프로세스를 선택해야한다. (시스템의 성능향상)
스케줄링 기준 >  프로세스의 특성(i/o 바운디드(i/o를 더 많이 쓰는 프로세스), 컴퓨트 바운디드(cpu를 더 많이 쓰는 프로세스)),프로세스의 긴급성 , 프로세스의 우선순위    
프로세스의 수행 > cpu 사용 + i/o 대기(cpu사용햇다가 i/o대기하고 반복적으로 일어난다) >> cpu burst(cpu사용시간) , i/o burst(i/o 대기시간) 그래서 버스트타임에 따라 스케줄링 기준이 달라짐
long term scheduling > job scheduling(시스템에 제출 할 작업 결정(생성단계)) , 다중프로그래밍 정도 조절(시스템 내 프로세스 수 조절) , 
아이오 바운디드와 컴퓨트 바운디드을 잘 섞어야함 (왜?? 시스템의 효율업을 위해), 시분할 시스템에서는 롱텀스케줄링이 덜 중요함
mid term scheduling > 메모리 할당 결정(서스팬드 레디에서 레디 단계)
short term scheduling> process scheduling ,프로세서를 할당할 프로세스를 결정(레디에서 러닝단계), 가장 빈번하게 발생하며 그래서 매우 빨라야함
선점(preemptive)/비선점 스케줄링 정책(non-preemptive) > 비선점 스케줄링 정책(할당 받을 자원을 스스로 반납할 때까지 사용, 선점 스케줄링(타의에 의해 자원을 빼앗길 수 있슴)
우선순위 정채 > 정적 우선순위(프로세스 생성시 결정된 우선순위가 유지), 동적 우선순위(프로세스의 상태 변화에 따라 우선순위 변경)
스케줄링 알고리즘
fcfs > 선착순, 비선점 스케줄링 정책 사용, 스케줄링 기준은 도착시간, 자원을 효율적으로 사용가능, batch(일괄처리) 시스템에 적합하다, interactive(대화형)시스템엔 부적합
rr(라운드로빈) > 일정시간만큼 돌아가면서 , 선점 스케줄링 정책 사용, 스케줄링 기준은 도착시간,  하지만 자원사용에 제한시간이 있슴!!(시간이 지나면 자원반납),대화형 시분할 시스템에 적합
spn(shortest-process next) >버스트타임이 가장 작은 프로세스를 먼저 처리, 비선점 스케줄링, 평균 대기시간 최소화, 부하 감소, 많은 프로세스들에게 빠른 응답시간 제공, 긴 프로세스는 무한대기현상 발생, 정확한 실행시간을 알 수 없음
srtn(shortest -remaining time next) > 선점 스케줄링, 잔여 버스트타임이 더 적은 프로세스가 선점됨, spn장점 극대화, 잔여실행을 계속 추적해서 부하가 크다, 구현 및 사용이 비현실적
hrrn(high-response-ratio-nest) > spn변형, 프로세스의대기시간을 고려하여 기회를 제공, 응답률이 높은 프로세스 우선 , spn의 장점이 있고 무한대기 방지
mlq(multi-level queue) > 여러가지의 ready queue를 가지며 각각의 queue는 자신만의 스케줄링 기법 사용, 최초 배정된 queue를 벗어나지 못하기에 변화적응이 힘들다. 
mfq > queue간 이동이 허용되는 mlq, 피드백을 통해 우선 순위 조정, 버스트타임를 예상하지 않고도 윗 기법의 효과를 낼 수 있다, 다양한 변형이 가능하며 i/o바운디드위주로 우선순위를짜서 효율성 증가,  구현이 복잡하며 무한대기 문제가 존재, 

다중프로그래밍 시스템 > 여러개의 프로세스들이 존재, 프로세스들은 독립적으로 동시에 동작, 하지만 같은 자원을 동시에 사용할 때 문제가 생김.
동기화 > 프로세스들이 서로 동작을 맞추는것, 정보를 공유하는것
비동기적이다 >> 프로세스들이 서로에 대해 모름
병행적이다 >> 동시에 프로세스들이 시스템에 존재하는 것
즉, 병행 수행중인 비동기적인 프로세스들이 공유자원에 동시접근할 때 문제가 발생
공유데이터 > 여러프로세스들이 공유하는 데이터
임계 영역(CS) > 공유데이터를 접근하는 코드영역
상호배제 > 둘 이상의 프로세스가 동시에 임계영역에 진입하는 것을 막는 것
기계어 명령의 특성 > 한 기계어 명령의 실행 도중에 인터럽트(방해) 받지 않음(원자성, 분리불가능) 그래서 실행순서에 따라 결과가 달라짐!! (1과2)그림2참조
이것을 해결하는 것이 '상호배제'   > 내가 여기를 실행하는 동안 다른애들이 이 영역에 못들어오게 해줘! (누가 임계영억에 들어가있으면 다른 애는 못들어온다)
상호배제의 기본연산 > 1.enterCS() (영역에 누가 있는지 진입 전 검사) 2.exitCS() (영역을 벗어났음을 알림)
전제 : 프로세스가 있으면 다른 프로세스의 진입 금지(상호배제) , CS안에 있는 프로세스외에는 다른 프로세스가 CS에 진입한느 것을 방해하면 안됨(진행),언젠가 진입할 수 있어야함(한정대기)   
상호배제의 알고리즘 솔류션 (여러 알고리즘 존재) 강의 6-1 
 소프트웨어 솔류션들의 문제점 > 속도가 느리고 구현이 힘들며 BUSY WAITING(CS진입전 계속 돌면서 대기하게됨)
 하드웨어 솔루션 >TestAndSet 명령어 사용함 장점은 test구현이 간단하지만 단점으로 여전히 busy waiting문제가 있다.
 os가 지원하는 소프트웨어 솔류션 > spinlock을 쓴다. 정수형 변수면서 p(s) ,v(s)  s는 물건갯수 p는 묽건을 꺼내느넛 v는 물건을 넣는것, 하지만 spinlock은 멀티 프로세서에서만 가능 ,busy waiting 여전히 존재
                                               > semaphore 음이 아닌 정수형 변수 p(), v() , spinlock과 다른점은 임의의 s변수 하나에 ready queue하나가 할당됨(레디큐는 일종의 대기실, 대기실에서 기다리기때문에 뺑뺑돌지않음 그래서 busy waiting을 해결)
                                                  문제점은  wake up 순서가 비결정적이라 무한대기할 수 있음
                                               > Sequencer 정수형 변수, 생성시 0으로 초기화, 발생 사건들의 순서 유지(은행 번호표!!), ticket()연산으로만 접근 , ticket(S(equencer))  
                                               > Eventcount 정수형 변수, 생성시 0으로 초기화, 특정사건의 발생횟수 기록, read(e), advance(e) await(e,v) 연산으로만 접근 // 둘다 busy waiting이 없고 무한대기도 없다, 순서도 컨드롤 가능
                                                  read(e) (현재 Eventcount값 반환)  advance(e)( e < e+1, e를 기다리고 있는 프로세스를 깨움) await(e,v)( if(e<v)이면 e에 연결된 대기실에 프로세스 전달 및 호출)
 language - level solution > 모니터 > 사용이 쉽고 에러발생 가능성이 낮다 , 단점으로 지원하는 언어에서만 가능하고 컴파일럭가 os를 이해하고 있어야함                                            

데드락 > 교착상태 (사이클형성)
blocked asleep state > 프로세스가 특정이벤트(필요한 자원)를 기다리는 상태
deadlock state > 발생 가능성이 없는 이벤트를 기다리는 경우 (sleep상태에 존재함)
데드락과 무한대기의 차이 > 데드락은 가능성이 아예없고 자원을 기다림,  asleep상태에 존재하는 것이며 무한대기는 운이없어서 계속 할당을 못받는 경우며 cpu를 기다림, 레디 상태에 존재한다.
자원에 대한 구분
선점가능한 자원 > 선점당한 후 돌아와도 문제가 발생하지 않는 자원 ex.프로세스 , 메모리
선점불가능한 자원 > 선점당하면 이후 진행에 문제가 발생하는 자원 ex.disk drive
total allocation resources > 자원전체를 프로세스에게 할당, ex. 프로세스 , disk drive > 하나만 할당할 수 있지만 모든 프로세스에게 할당가능하다.
partitiomed allocation resources > 하나의 자원을 나누어 여러 프로세스에게 할당 ex. 메모리
exclusive allocation resources > 할당한 영역을 한 순간에 한 프로세스만 사용 가능한 자원 ex. 프로세스 메모리 디스크 
shared allocation resources > 여러프로세스가 동시에 사용 가능한 자원 ex.source code, exe파일 
serially reusable resources > 시스템 내에 항상 존재하는 자원, 사용이 끝나면 다른 프로세스가 사용 가능 ex. 프로세스, 메모리 디스크 프로그램
consumable resources > 한 프로세스가 사용한 후에 사라지는 자원 ex. 시그널
데드락을 발생시킬 수 있는 자원의 형태 > 선점불가능한 자원, exclusive allocation resources,serially reusable resources 
데드락 필요조건(4가지가 성립되어야 발동) > exclusive use if resourses, 선점불가능한 자원[자원의 특성] 
/ hold and wait(partial allocation) (자원을 홀드한 상태에서 다른 자원을 요청) , circular wait(관계가 사이클이 될때)
데드락 예방방법 > 4가지중 하나를 제거하면 됨. >>결과적으론 어느하나도 제거할 수 없다..(비현실적이고 자원낭비가 심함)
1. 모든 자원을 공유 허용 > 현실적으로 불가능 2.모든자원에 대해 선점 허용 >현실적으로 불가능 
3. 필요한 자원 한번에 모두 할당 > 자원 낭비 발생, 무한 대기 현상 발생 가능 4.사이클 제거 > 자원들에게 순서를 부여해서 순서의 증가 방향으로만 자원 요청 가능하게 만들면된다. (데드락강의 3/5 9:28초) 하지만 낭비 발생
데드락 회피방법 > 시스템의 상태를 계속 감시!!하고 시스템이 데드락상태가 될 가능성이 있는 자원 할당 요청을 보류한다 즉. 시스템을 항상 safe state로 유지!!!
safe state > 모든 프로세스가 정상적 종료 가능한 상태(safe sequence(모든 프로세스가 정상적으로 종료 가능한 상태(경로가 존재함))가 존재해야함)
데드락 회피방법의 가정 > 1. 프로세스수, 자원의 종류와 수가 고정 2.프로세스가 요구하는 자원 및 최;대수량을 알고잇어야함 3. 프로세스는 자원을 사용 후 반드시 반납 >>> 1,2번은 실용적이지 못하다
뱅커스 알고리즘 > safe sequence(모든 프로세스가 정상적으로 종료되는 경로)가 존재하느냐에 따라 자원을 할당해줌
habermann의 알고리즘 > 여러종류자원을 사용하는 알고리즘 뱅커스 알고리즘과 똑같지만 여러종류 자원을 사용한다는 차이
데드락 회피의 문제는 시스템을 항상 감시하기 떄문에 높은 부하가 일어나며 safe state를 유지하기 위해 사용되지 않는 자원이 존재하며(자원효율이 낮음) 현실적이지 못함(1. 프로세스수, 자원의 종류와 수가 고정 2.프로세스가 요구하는 자원 및 최;대수량을 알고잇어야함)
데드락 탐지방법 > 피하지 않고 해결! > resource allocation graph(데드락 검출을 위해 사용)
 resource allocation graph방법 > 검사주기 영향이랑 노드수가 많으면 높은 부하가 생김
unblocked process > 필요한 자원을 모두 할 당 받을 수 있는 프로세스(자원요청수<=남은자원 수라면 프로세스는 모든 자원을 할당받을 수 있다)
 resource allocation graph 절차 > 1. unblocked process에 연결된 모든 엣지(연결고리)를 제거 하고 2. 더이상 unblocked process가 없을 때까지 1을 반복
최종 resource allocation graph에서는 모든 엣지가 제거되어 현재 상태에서 데드락이 없거나 엣지가 남아 데드락이 존재한다.
데드락회피는 최악의 경우를 생각 즉 데드락이 발생하지 않음, 데드락해결은 최선의 경우를 생각 즉 데드락 발생시 해결과정이 필요!
데드락 recovery 방법 > 데드락을 검출 한 후 해결 하는 과정
방법 1. process termination > 데드락 상태에 있는 일부 프로세스를 종료 시킴(종료시킬 프로세스 선택과 기준이 필요함), 강제 종료된 프로세스는 이후 재시작됨.
비용이 적은 프로세스부터 종료 > 부하 낮고 간단하지만 불필요한 프로세스들이 종료 될 가능성 있슴
최소비용으로 종료 > 모든 경우의 수를 고려하기 떄문에 복잡하고 부하가 높다.
       2. resource preemption > 데드락 상태 해결을 위해 선점할 자원 선택(선택기준이 필요함), 선정된 자원을 가지고 있는 프로세스에서 자원을 빼앗음 (자원을 빼앗긴 프로세스는 강제 종료됨)
       3. checkpoint restart method > 특정지점마다 저장하여 강제종료하더라도 처음부터가 아닌 체크포인트부터 재시작하는 방법

레지스터,캐시는 하드웨어(cpu)가 관리 / 메인메모리와 보조기억장치는 소프트웨어(운영체제)가 관리
block 보조기억장치와 주 기억장치 사이의 데이터 전송단위 size 1~4 4kb
word 주기억장치와ㅣ 레지스터 사이의 데이터 전송단위 size 16~64bits
address binding > 메모리에서 데이터가 어디있는지 알 수 있는 물리주소와 논리주소를 묶어(매핑)주는 작업
그림3 참조 (시점마다 차이)
compile time binding 특징 > 프로세스가 메모리에 적재될 위치를 알고있어야하며 위치가 변하면 안됨. 
load time binding 특징 > 컴파일 시점에서 적재위치를 모르면 대체가능한 상대주소를 생성함. / 적재시점의 시작 주소를 반영하여 사용자 코드 상의 주소를 재설정함
run time binding 특징 > 프로그램은 레디 러닝 블락 상태를 왓다갓다하기때문에 러닝에 올라갈때마다 주소가 변경됨 / 대부분의 os가 이렇게 사용됨.
dynamic loading > 모든 루틴을 교체가능한 형태로 디스크에 저장하고 프로세스가 호출할때 메모리에 올린다!(로틴의 호출시점에 바인딩 수행) 그래서 메모리 공간의 효율성이 향상
memory allocation(메모리 할당)
연속할당 > 연속된 메모리 공간에 프로세슬르 할당하는 정책 / 메모리 구성정책 : 메모리 내 동시에 올라갈 수 있는 프로세스 수, 메모리 분할 방법 ,각 프로세스마다 할당가능한 메모리 공간 크기
             > uni-programming > 프로세스가 한번에 하나만 올라감 
                문제점1. 메모리보다 프로그램 크기가 더 큰경우 >>해결책 : 분할해서 올려야함 overlay structure: 공통된 부분만 올려놓고 필요할때마다 구분해서 따로 번갈아가면서 올리는 것(즉 모메리에 현재 필요한 영역만 적재)
                         2. 커널을 보호(프로그램 크기가 커서 커널영역을 침범할 수 있기때문) >> 해결책: 경계 레지스터(커널과 프로그램의 경계선에 경계레지스터를 둠으로 침범못하게 함)
                         3. 시스템활용도가 낮다 (메모리 자리가 남을 수 있다) 
             > multi programmming > uni-programming의 문제점을 해결
                                              > fixed partition multi programmming >메모리 공간을 고정된 크기로 미리 분할(여러방으로 나눔,그래서 메모리 관리가 간편), 한 방에는 프로세스 하나만 적재 / 영역침범때문에 각 방 사이마다 경계 레지스터를 놓는다.
                                                                                                   >interal fragmentation(내부단편화) > 프로그램 크기보다 방의 크기가 더 커서 프로그램을 적재하고 나서 낭비되는 방의 메모리가 있는 경우를 말함 즉 자원이 낭비됨
                                                                                                   >external fragmentation(외부 단편화) > 남은 총 메모리 공간은 충분하지만 맞는 방의 크기가 없어서 못들어가는 경우                                        
                                              > variable partition multiprogramming >초기에는 전체가 하나의 영역이지만 프로세스를 처리(요청)하는 과정에서 메모리 공간을 유동적으로 분할 (내부단편화가 일어나지않음) 
                                                                                                   >배치전략(처리가 끝나고 나갓을 때 분할된 그대로 공간이 남음 거기서 다른 프로그램이 들어올때 어디에 배치하느냐)
                                                                                                                 >최초적합 > 충분한 크기를 가진 첫번째 공간을 선택 (간단하고 부하가 작지만 공간활용률이 떨어짐)
                                                                                                                 >최적적합 > 프로세스가 들어갈 수 있는 공간 중 가장 작은 곳선택(큰 공간을 유지할 수 있지만 작은 크기의 공간이 많이 생기고 부하가 크다)
                                                                                                                 >최악적합 > 가장 큰곳을 들어감(부하도 크고 큰 크기의 공간확보가 어렵지만 작은크기의 공간은 줄일 수 있다.)
                                                                                                                 >순차 최조 적합 > 마지막으로 주었던 위치부터 탐색하여 공간을 선택 (메모리 사용빈도 균등화 ,낮은 부하) 
                                                                                         >외부단편화 이슈             
                                                                                                                 >공간통합 > 들어올 프로세스가 기다렷다가 한 프로세스가 나가면 인접한 빈영역을 하나의 공간으로 합쳐서 그 공간에 들어감(낮은 부하)
                                                                                                                 >메모리 압축 > 모든 빈 공간을 한쪽으로 모아서 하나로 통합(모아서 하나로 통합하기 때문에 프로세스의 재배치가 필요하고 재배치중에는 프로세스는 중지 즉, 자원소비가 심하고 부하가 크다)
비연속할당 > 프로그램이 메모리에 올라갈때 프로그램을 여러개의 블럭으로 분할하여 비연속적(띄엄띄엄)으로 적재하며 실행 시 필요한 블럭들만 메모리에 적재한다. 나머지 블럭들은 swap device에 존재
                > 비연속할당에서는 address mapping은 가상주소(논리주소이며 연속된 메모리 할당을 가정한 주소이다)를 만들고 실제주소(실제 메모리에 저재된 주소)로 바꿔주는 것이다.
                > block mapping > 사용자 프로그램을 블럭단위로 분할/관리하는것 >> block map table(BMT)로 address mapping정보 관리(커널 안 프로세스마다 하나의ㅏ BMT를 가짐) 
                > 가상주소 >> bmt >> 메인메모리 순으로 이동. 
                > paging system(프로그램을 같은 크기의 블록으로 분할하고 메모리를 블럭사이즈로 미리 분할)/블럭들은 가상메모리(swap device)에 존재( /page(분할된 블럭) /page frame(페이지와 같은 크기로 미리 분할된 메모리상의 공간)
                                       >특징: 크기에 따른 분할이며 간단하며 효과적이고 외부단편화는 없지만 내부단편화가 있다, 메모리 통합 및 압축 불필요하지만 논리적 구조를 고려하지않아 쉐어링과 프로텍션이 복잡
                                       >address mapping > page map table(PMT)을 사용해서 매핑한다.
                                                                  > 3가지 매커니즘 1.직접매칭(block mapping과 유사) /문제점:메모리 횟수가 2배라 성능저하, pmt를 위한 메모리 공간필요 *page fault(residence bit이 0인 경우(아지 메모리에 적재되지 않음))
                                                                                           2.associative mapping(직접매핑의 단점의 해결책) >translation look aside buffer(TLB)에 PMT 적재/ TLB(PMT전용 하드웨어)를 사용하면 병렬탐색을 하고 TLB자체에서 계산하기 때문에 빠르게 주소 값이 나오며 부하도 적다. 하지만 비싸기때문에 큰PMT를 다루기 힘듬
                                                                                           3.hybrid mapping > 두 기법을 혼합(하드웨어 비용은 줄이고 associative mapping장점활용) / 작은 크기의 tlb를 사용하고 pmt중 일부들만 tlb에 적재(최근 사용되었던 page들에 대한 pmt를 올린다 >지역성)
                                                                                              최근에 읽은 적이 있으면 바로 tlb로가고 없으면 메모리 상 pmt로 감 (즉, 최근전적이있다면 associative mapping방식으로 가고 없다면 직접매핑 방식으로 간다)   
                                        >메모리 관리방법 > FPM과 비슷 / page frame을 만들어서 관리 사용 /  frame table > 페이지 프레임당 하나의 공간을 준다/ 구성: 할당받앗거나 사용가능한 필드, pid 필드(할당한 프로세스 아이디), 링크필드(비어있는 공간에 대한 리스트, av(빈 공간을 찾기 위한 포인터 즉, 가장 처음 비어있는 공간을 지칭)        
                                                                 > page sharing > 비연속성이기에 여러 프로세스가 특정 page를 공유할 수 있다.( 코드, 읽기전용데이터, 읽기쓰기 데이터들을 공유해서 사용가능)
                                                                 > procedure page sharing 문제점 > 공유하는 page가 엉켜서 이상한곳에 배치될 수있다 / 해결책: shared page에 대한 정보를 pmt 내 같은 공간에 저장(이름을 같게함)
                                                                 > page protection > 페이지를 공유한다는 것은 침해가 가능하다 그래서 페이지를 지키기 위해 protection bit을 사용한다. 해당 페이지에게 할 수 있는 것을 정해 적어 놓는다.(페이지에 대한 접근 권한을 관리)
                >segmentation system > 프로그램을 논리적 블럭으로 분할(같은 크기가 아닌 상황에따라 다른 크기로 분할) /segment(논리적으로 분할된 블럭)/ 특징: 메모리를 미리 분할 하지 않음 , 공유하거나 보호학기에 용이하며 하지만 관리가 복잡해서 부하가 크다 내부단편화는 발생하지 않지만 외부 단편화 발생 가능
                                                >adress mapping> segment map tap(SMT)를 이용 (paging system이랑 비슷하지만 세그먼트 길이(크기가 다르기때문)와 프로텍션 빗츠(논리적으로 블럭을 나누기에 권한이 중요)가 추가됨)                                               
                                                                       > 매커니즘은 paging system과 비슷하다 (직접매핑 > smt단계에서 허가되지 않은 연산의 경우 프로텍션 빗츠를 검사, 변위가 segment 길이보다 큰경우 오버플로우 처리 모듈 호출 >> 메모리 적재)
                                                >메모리 관리방법 > segment 적재 시 크기에 맞추어 분할 후 적재, VPM과 비슷
                                                                         > 논리적으로 분할되어 있어 공유 및 보호가 용이
                >hybrid paging/segmentation system> paging 과 segmentation의 장점 결합, 논리단위의 segment로 분할하고 각 segment를 고정된 크기의 page들로 분할하며 page 단위로 메모리에 적재.
                                                                   >adress mapping > smt와 pmt 모두사용, 각 프로세스마다 하나의 smt 사용하며 각 segment마다 하나의 pmt 
                                                                   > 메모리 관리 > page가 메모리에 올라가기 때문에 FPM과 비슷 / residence bit(세그먼트에서 메모리로 적재되지 않기때문)은 없지만 pmt주소(세그먼트에서 페이지로 바뀌기때문)가 존재
                                                                   > 장점: 공유 보호가 쉽고 메모리할당 관리가 쉬워 부하가 적으며 외부단편화는 일어나지 않는다.
                                                                   > 단점: 전체 테이블 수가 증가하여 메모리 소모가 크고 adress mapping과정이 복잡하며 직접매핑을 할 경우 메모리 접근이 3배(이 부분은 전용하드웨어를 사용해서 해결가능

가상메모리(기억장치) > 비연속할당하며 프로그램을 블럭단위로 나누어서 필요할때 메모리에 적재하는 시스템 ex.paging / segmentation
가상메모리 관리 목적 > 가상메모리 성능 최적화하는 것! > page fault 비율을 최소화할 수있는 전략이 필요, 즉, page fault가 발생한다는 것은 비용이 증가한다는 것(그만큼 context switch 및 커널 개입이 많아지므로)
page reference string > 프로세스의 수행 중 참조한 페이지 번호 순서 
page fault 비율 > 참조했던 실행하면서 참조했던 페이지의 수 에서  page fault일어난 수를 나눔
가상 메모리를 쓰기위한 여러가지 장치 > 하드웨어 > addess translation device >adress를 변환하는 장치 ex.TLB
                                                                     > bit vectors > page 사용 상황에 대한 정보를 기록하는 비트들(PMT안에 있다) 
                                                                                          종류: 1. reference bits(used bits) 페이지 프레임이 최근에 참조되엇는지 표시 (프로세스에 의해 참조되면 해당 PAGE를 BIT를 1로 설정하고 특정 주기마다 모든 reference bits를 0으로 초기화) 
                                                                                                  2.update bits(dirty bits) 페이지 프레임에 있는 정보가 갱신(수정)되었가 (주기적인 초기화는 없고 수정되면 1로 설정 / 해당 PAGE의 메모리와 가상메모리 내용은 다르다 왜?? 프로세스는 메모리에서 일하기 때문 그래서 가상메모리에 write back이 필요)
                                                     > 소프트웨어 > 할당전략 > 각 프로세스에게 메모리를 얼마만큼 줄것인가? > fixed allocation > 고정된 크기의 페이지 프레임을 메모리를 할당  / variable allocation > 할당하는 메모리의 크기가 유동적 
                                                                                        > 그래서 얼만큼 줘야하나?? 정답은 적당히(필요한 메모리 양을 예측하는 것이 중요)!!! 너무 큰 메모리 할당하면 낭비이고 너무 적게주면 성능이 저하됨.                                           
                                                                        > fetch전략 > 특정 page를 메모리에 언제 적재할 것인가? > demand fetch > 참조할때 페이지를 적재 (필요한 페이지를 적재) / page fault 부하가 있다.
                                                                                                                                                       > anticipatory fetch > 참조될 가능성이 높은 page를 예측해서 미리 적재 / 예측에 성공하면 page fault 부하가 없음 대신 예측 실패시 부하가 크다.
                                                                                         > 대부분은 demand fetch를 사용한다/ 일반적으로 준수한 성능 보여줌
                                                                        >배치전략 > 연속할당 배치전략에서 배움
                                                                        >replacement(교체)전략 > 새로운 page를 어떤 page와 교체할 것인가? (빈 page frame이 없는 경우)
                                                                                                          > fixed allocation  > MIN algorithm > page fault 빈도를 최소화시키는 알고리즘/가장 오랫동안 참조되지 않을(예상) page를 교체함!/하지만 실현 불가능한 기법이다(참조 순서를 미리 알고있어야함) / 성능평가도구로 사용됨
                                                                                                       (메모리할당량 고정)  > random algorithm > 무작위로 교체할 page 선택 / 부하가 적고 정책이 없다.
									     > fifo > 먼저들어온거 먼저 내보냄(가장 오래된 페이지를 내보냄) 즉, 적재된 페이지의 시간을 알고있어야함 / 자주 사용되는 page가 교체될 수있음( 지역성 고려가없다)
                                                                                                                                   > lru(least recently used) > 가장 오랫동안 참조되지 않은 page를 교체 / page 참조 시마다 시간을 기록해야함(부하가 크다(순서만 기록해서 부하 감소)) / 지역성을 고려함 /실제로 많이 쓰임 /loop실행에선 page fault가 급격히 증가될 수 있음
                                                                                                                                   > lfu(least frequently used) > 가장 참조 횟수가 적은 page를 교체 / 참조 마다 참조횟수를 누적(부하 증가) / lru보다 적은 부하 / 지역성을 고려함 / 다음 참조될 가능성이 높은 page가 교체될 가능성이 있다.
                                                                                                                                   > nur(not used recently) > bit vector을 사용하여 최근에 참조가 안된 page를 교체 / lru보다 적은 부하로 비슷한 성능 달성 목적 /  reference bits가 0인 것을 우선으로하고 다음 update bits가 0인것을 우선으로 교체
                                                                                                         > variable allocation > 성능평가를 할때 평균할당되는 page frame의 수와 page fault를 같이 보고 판단해야한다. *window: 현재 바라보는 영역
                                                                                                          (메모리할당량 변함) > working set algorithm > 특정시간에 자주 참조하는 page들의 집합 [t-x,t]사이의 시간 /지역성 고려 / 적재되는 page가 없더라도 메모리를 반납하는 page가 생길 수있다. / page fault비율 감소와 시스템 성능 향상 하지만 지속감시가 필요하므로 비용 증가 / window size는 고정
                                                                                                                                     > page fault frequency algorithm(pff) > 지속감시는 비용이 증가하므로 page fault가 나면 관리! / 페이지폴트가 적으면 메모리할당을 줄여주고 페이지폴트가 많으면 메모리할당을 늘려준다 / 낮은 부하 /*inter fault time(페이지 폴트 간 사이의 시간) /ift>t 이라면 페이지폴트 적음 반대라면 큼   
                                                                                                                                     > variable min algorithm > 평균메모리 할당량과 page fault 발생횟수 모두 고려 / 하지만 실현불가능(페이지의 참조되는 순서를 알고 있어야함) / 한 페이지가 일정 시간안에 참조되면 그 페이지가 다른 일정시간사이에 다시 참조되는지 확인, 참조되면 유지하고 안되면 메모리에서 내림                    
                                                                        >cleaning전략 > 변경 된 page를 언제 write-back 할 것인가? >demand cleaning > 해당 page가 메모리에서 내려올때
                                                                                                                                                           >예측 cleaning > 더이상 변경될 가능성이 없다고 판단할때 미리 write-back
                                                                                            > 실제 대부분은 demand cleaning을 사용 (일반적으로 준수한 성능)
                                                                        >load control전략 > 시스템 내 프로세스의 수를 조절(할당전략과 연계) 
                                                                                                 > 적당히 수를 유지하는 것이 중요!! 저부하상태는 자원을 낭비하고 성능이 저하된다. 고부하상태는 성능이 저하되고 스레싱현상발생(너무 많은 프로세스가 자원을 요청하면서 page fault가 많이 일어남)
                                                        >그 외의 고려요소 > page size > 적당한 것이 좋다/ 하지만 요즘은 점점커지는 경향(메모리 사이즈가 커지고 있기때문에 페이지 사이즈도 상대적으로 커지고 있다 너무 작으면 page fault비용이 증가하기때문)                 
                                                                                                   > 페이지 사이즈가 작을경우 > 페이지 수가 많아짐 즉, 부하가 높아짐 / 내부단편화 감소/지역성향상/page fault 증가/ 여러개 올려야해서 입출력시간증가
                                                                                                   > 페이지 사이즈가 클경우 > 페이지 수가 작아지고 즉 부하가 작아짐 / 내부 단편화 증가/지역성감소/page fault 감소/ 조금만 올려도 되서 입출력시간감소
                                                                                  > program restructuring > 프로그램의 구조를 변경하여 성능을 높일 수 있다 ex.행열을 바꾸는 것만으로도 page fault를 줄일 수 있다 (지역성) 
                                                                                  > TLB reach >TLB를 통해서 접근할 수 있는 메모리 범위 또는 양 / 공간 수 * 페이지 사이즈 / 접근범위가 높아지면 많은 페이지들이 접근가능해지면서 성능증가 
                                                                                                     1.TLB증가 >하지만 비쌈 / 2. page 크기 증가 or 다양한 page size 지원 > 큰것만이 능사는 아님! 

disk system > disk pack: 데이터 영구 저장 장치 > 구성: sector: 데이터 저장/판독의 물리적 단위 / track: 한 면의 sector들의 집합 / cylinder: 같은 반지름을 갖는 track의 집합 / platter: 데이터의 기록/판독이 가능한 기록매체 / surface
                > disk drive(HDD형태): disk pack에 데이터를 기록하거나 판독 할 수있도록 구성된 장치 > 구성 > head:디스크 표면에 데이터를 기록/판독 /arm:head를 고정,지탱 / positioner:arm을 지탱 head를 원하는 track으로 이동 /spindle:disk pack을 고정, 분당회전수(rpm) (성능에 중요[빨리 읽을 수 있음])                                                  
                >disk address > physical disk address > sector를 지정 
                                   > logical disk address > disk system 전체를 블럭들의 나열로 취급하여 블럭에 번호를부여한다 / 블럭에 번호를 부여하기 위해선 physical address 모듈(disk driver)이 필요
                >데이터 액세스 과정 > 1.seek time >헤드를 필요한 실린더로 이동하는 시간 2.rotational delay > 필요한 sector가 head 위치로 도착하는 시간 3.data transmission time > 해당 sector를 읽어서 전송하는 시간
file system >사용자들이 사용하는 파일들을 관리하는 윤영체제의 한 부분 
               > 구성 > files: 정보의 집합 / dirrectory structure : 시스템 내 파일들의 정보를 구성 및 제공(파일들을 모아두는 곳 ex.폴더 디렉토리) / partitions: directory드르이 집합을 논리적/물리적으로 구분(c,d드라이브)
                         > file > 보조 기억 장치(disk)에 저장된 연관된 정보들의 집합이다. / 보조 기억 장치 할당의 최소 단위 /bite들의 집합
                                 > os는 파일 기능들에 대한 system call을 제공해야함!!
                                 > file access 방법 > sequential access > 레코드 단위로 순서대로 접근하는 방법
                                                          > directed access > 원하는 블럭을 직접 접근하는 방법
                                                          > indexed access > 목차를 참조하여 원하는 블럭을찾은 후 데이터에 접근
                         > directory > file들을 분류, 보관하기 위한 개념
                                        > flat directory structure > fs내에 하나의 directory만 존재 /단점: 파일 이름 문제(하나밖에 없어서 이름이 중복될 수있다), 파일 보호문제(중복으로 덮어쓸 수 있다), 파일관리가 어려움
                                        > 2 level directory structure > 사용자 마다 하나의 directory를 배정해서 다중 사용자들이 사용할 수 있다. 이름 중복 파일보호 문제 해결 / 단점: sub directory 생성불가 , 한 파일을 공유하려면 directory 전부를 엑세스해야하기에 공유불가능
                                        > hierarchical directory structure > tree 형태의 계층적 directory 사용가능 / 사용자가 sub directory를 생성 가능(os가 system call을 제공해야함) /대부분의 os가 사용중
                                                                                     > home directory > 쓸 수 잇는 가장 최상단 디렉토리
                                                                                     > current directory > 현재 자신이 위치한 디렉토리 
                                                                                     > absolute pathname > 절대 경로: 홈 디렉토리로부터 최종 목적이 되는 디렉토리까지 경로 
                                                                                     > relative pathname > 상대 경로: 현재 위치한 디렉토리로부터 최종 목적이 되는 디렉토리까지 경로
                                        > acyclic graph directory structure > hierarchical directory structure의 확장/ link개념 사용 > 바로가기!! / directory안에 shared directory , shared file을 담을 수 있음(링크를 넣을 수 있슴!) 
                                        > general graph  directory structure > 링크 cycle을 허용                                                   
                         > partition >논리적으로 나눈 디스크(하나의 하드디스크를 둘또 그이상으로 나누어 서로 다른 두개의 하드디스크를 만든것) / 하드디스크 >물리적으로 나눈 디스크
file protection > file에 부적절한 접근 방지(다중사용자 시스템에 더욱필요)
                    > 1. 패스워드 기법 > 각 파일에 pw부여 / 비현실적(사용자들이 파일 각각에 대한 pw를 기억해야함/ 서로 다른 pw를 부여해야함)
                    > 2. access matrix 기법 > 도메인과 오브젝트 사이의 접근 권한을 명시(접근 권한을 표에다 명시) / object: 접근 대상(파일) , domain:접근 권한의 집합(사용자) / ex. d1에대한 f1,f2은 리드만 f4는 리드 라잇 모두 
                                                    > 실제 활용법 > global table > 전체 파일들에 대한권한을 table로 유지 / 메트릭스를 만들어 권한을 통째로 저장(빈공간도 저장)(크기가 커져서 부하가 크다)  <그림 4>
                                                                        > access list > 열(파일)을 중심으로 권한을 저장 (빈공간 저장 x) / 파일 생성 시 각 도메인에 대한 권한 부여 / 실제 os에서 많이 사용 /하지만 접근할 때마다 검사해야함(부하가 커짐) / 하지만 오브젝트별로 권한 변경이 용이함 (빠르게 가능)
                                                                        > capability list > 행(도메인)을 중심으로 권한을 저장 (빈공간 저장 x) / capability를 가짐이 권한을 가짐을 의미(신분증처럼) / 그래서 접근할때마다 검사 안해도됨(신분증이 있기때문) / capability list자체를 보호해야함(부하가 커짐) 그리고 오브젝트별로 권한변경이 어렵다(귀찮다)
                                                                        > lock-key mechanism > access list와capability list혼합 / 오브젝트에 lock을 도메인은 key를 가지고 둘이 맞다면 접근가능 / 시스템은 key list를 보호해야함 (부하가짐)
                                                                        >실제 많이 쓰는 방법 >access list와capability list 개념을 함께 사용 / 오브젝트에 첫 접근하면 access list를 탑색하고 허용시 capabillity 생성해서 이후 접근시 권한 검사를 생략하고 마지막 접근 후 capability를 삭제한다.
allocation methods > continuous allocation > 한 파일을 디스크의 연속된 블럭에 저장 / 효율저으로 파일에 접근 가능(순차 ,직접접근) /문제점: 새로운 파일을 위한 공간확보가 어려움, 외부 단편화가 일어날 수 있다, 이후 파일이 커지는 경우도 고려해야해서 공간 크기 결정이 어려움
                             discontinuous allocation > linked allocation > 파일이 저장된 블록들을 linked list로 연결(비연속 할당가능) /구현이 간단하며 외부 단편화가 없다 / 문제점: 직접접근할때 비효율적이고 포인터 저장을 위한 공간이 필요하다 
                                                                                         > file allocation table(FAT) > 각 블록의 시작 부분에 다음 블록의 번호를 기록하는 방법 (링크방식!! 서로 이어지게끔) / 실제로 많이 쓰임
                                                               >indexed allocation > 파일이 저장된 블록들의 정보를 목차블럭에 모아둠 / 직접접근에 효율적이며(목차를 쓰는 이유를 생각해봐라) 순차접근엔 비효율적 / 파일마다 인덱스 블럭을 유지해야하므로 추가 공간이 필요하며 인덱스블럭의 크기에 따라 파일의 크기가 제한됨
free space management > bit vector > 각 블럭에 대해 빈블럭이면 0, 할당 블럭이면 1로 표시 / 간단하고 효율적 / 하지만 bit vector 전체를 메모리에 보관해야함(대형 시스템이면 더욱 많은 공간을 필요하기에 부적합) 
                                 > linked list > 빈 블럭을 linked list로 연결 / 링크라는 공간을 가지고 있어야하며 일일히 하나씩 따라가기때문에 탐색시간도 비효율적 
                                 > grouping > n개의 빈 블럭을 그룹으로 묶고 그룹단위로 linked list로 연결 / 연속된 빈 블럭을 쉽게 찾을 수 있음 
                                 > counting > 테이블을 만들어 연속된 빈 블럭들 중 첫번째 블럭의 주소와 연속된 블럭의 수를 테이블로 유지 / 연속할당시스템에 유리하다.

i/o시스템 > procsessor controlled memory access 방법> 프로세서가 모든 데이터 전송을 처리해야함(프로세서가 계속 감시해야하기 때문 부하가 높음) [입출력장치 > 프로세서 > 메모리]
                                                                          > pooling 기법 > 프로세서가 주기적으로 i/o장치의 상태 확인(프로세서가 i/o한테 줄거 있냐고 물어봄)
                                                                                               > 간단하고 i/o장치가 빠르면서 데이터 전송이 잦은 경우 효율적이다. / 단점: 프로세서의 부담이 큼(계속 물어봐야하기 때문)(부하가 있다)
                                                                          > interrupt 기법 > i/o장치가 자업을 완료한 후 자신의 상태를 프로세서에게 전달(i/o장치가 프로세서한테 줄께있다고 하는것) interrupt발생시 프로세서는 데이터 전송을 수행
                                                                                                > pooling 대비 작은 부하 , 불규칙적인 요청 처리에 적합 / 단점: 계속 i/o장치가 찌르면 부하가 높아짐
              >direct memory access 방법 > i/o장치와 memory사이의 데이터 전송을 프로세서 개입 없이 수행(프로세서의 부하를 줄여준다)(프로세서는 데이터 전송의 시작/종료만 관여한다, DMA제어기가 나머지처리) [입출력장치 > 메모리]
운영체제의 i/o서비스 > 커널 안 커널 입출력 서브시스템이 i/o서비스를 담당
                              > i/o scheduling > 입출력 요청에 대한 처리 순서 결정해줌 
                              > error handing > 입출력 중 발생하는 오류 처리
                              > i/o 기기 정보 관리
                              > buffering 기법 > i/o장치와 프로그램 사이에 전송되는 데이터를 buffer에 임시 저장(입력에서 출력으로 가는 데이터 양을 모아두는 임시 창고를 만들어 디스크로 이동되는 속도에 맞게 보내줌)  / 전송 속도 차이 문제 해결                                                  
                              > caching > 자주 사용하는 데이터를 미리 복사해둠
                              > spooling 한 i/o장치에 여러 프로그램이 요청을 보낼 시 출려이 섞이지 않도록하는 기법(여러가지 요청이 왔을 때 요청들을 disk file에 기록하고 하나 요청의 기록이 다 모이는 순서대로 한번에 하나씩 i/o장치에 전송)
disk scheduling > disk access 요청들의 처리 순서 결정
                      > 평가기준 1. throughput(단위 시간당 처리량) 2. mean response time(평균 응답 시간) 3.predictability(응답시간의 예측성)
                      >seek time단계의 최적화 방법 > fcfs >요청이 도착한 순서에 따라 처리                  
                                                                > shortest seek time first(sstf) > 현재 헤드 위치에서 가장 가까운 요청먼저 처리 / 장점: 쓰루풋이 높고 평균 응답시간이 빠름 / 단점: 예측성이 떨어지고 무한대기 가능성/일괄처리 시스템에 적합
                                                                > scan 알고리즘 > 현재 헤드의 진행 방향에서 헤드와 가장 가까운 요청 먼저 처리, 마지막 실린더에 도착 후, 반대 방향으로 진행 / 장점: sstf의 무한대기 문제 해결, 쓰루풋 평균응답시간 우수 / 단점: 진행 방향 반대쪽 끝의 요청들의 응답시간 늘어남
                                                                > c- scan 알고리즘> scan과 유사하지만 헤드가 미리 정해진 방향으로만 이동, 마지막 실린더에 도착 후 시작 실린더로 이동후 재시작 / 장점: scan 대비 균등한 기회 제공 /단점: 시작 실린더로 돌아가기때문에 대비 비효율적
                                                                > look 알고리즘(엘레베이터 알고리즘) > scan에서 현재 진행 방향에 요청이 없으면 방향 전환(마지막 실린더까지 이동x) /장점 scan의 불필요한 이동 제거
                      >rotatuinal delay단계의 최적화 방법 > shortest latency time first(sltf) > 헤드가 고정된 디스크 시스템에 사용(모든 실린더에 헤드가 들어가있음)(그래서 헤드가 움직일 필요가 없음)
                                                                                                                    > 섹터마다 큐를 만들어 요청들을 미리 넣어놓고 각 섹터에 도착할때마다 큐를 읽어서 요청을 처리하면서 넘어간다 (그렇게 해서 회전수를 줄인다)
                                                                                                                    > 헤드가 움직이는 디스크 시스템에는 같은 실린더에 여러개의 요청처리를 위해 사용 가능        
                                                                        > shorest positioning time first(sptf) > positioning time = seek time + rotational delay / positioning time이 가장 작은 요청 먼저 처리 / 정점: 쓰루풋이 높고 평균 응답시간이 빠름 / 단점: 가장 안쪽과 바깥쪽의 실린더의 요청대한 무한대기 발생가능성
                                                                                                                         > eschenbach 기법 > 디스크가 1회전 하는 동안 실린더의 요청을 처리 /한 실린더에 다수의 요청이 있는 경우 다음 회전에 처리됨   
raid architecture > raid란? 여러개의 물리 disk를 하나의 논리 disk로 사용 / 디스크 시스템의 성능 향상을 위해 사용 
                       > raid 0 > disk striping >논리적인 한 블럭을 일정한 크기로 나누어 각 disk에 나누어 저장(병렬저장) / 장점: 한 디스크가 4개 읽어서 4초가 걸릴 것을 4개의 disk가 읽기 대문에 1초밖에 안걸림(성능 향상) /단점: 한 디스크에서 장애가 발생시 데이터를 읽지 못함
                       > raid 1 > disk mirroring > 동일한 데이터를 disk에 중복 저장 / 최소 2개의 disk가 필요 /장점: 한 disk가 손상이 나도 데이터 손실x /단점: 전체disk용량이 반으로 줄어듬 (정보가 중요한 시스템의 경우 사용)
                       > raid 3 > raid 0 + parity disk > parity disk를 이용하여 에러를 찾아내고 고칠 수 있는 패러티들을 저장 /raid 3에서는 byte단위로 분할하기에 각 디스크에 a0 a1 a2 a3이 저장됨 (raid0은 각 디스크에 a b c d) / 단점: 읽을때마다 패러티 생성 필요 즉, 부하가크다. ,패러티 생성에 몰리기때문에 읽는 것이 많으면 병목현상 가능
                       > raid 4 > raid 3와 유사하지만 블럭단위로 분산저장(블럭단위라서 독립적으로 엑세스가 가능 , raid3 이하는 엑세스할때 a를 한꺼번에 해야함) / 단점: 병목현상으로 성능 저하 가능( 독립적이기에 한쪽 디스크에만 몰릴 수 있다)
                       > raid 5 > raid4와 유사하지만 패러티 디스크를 따로 만들지 않고 각 디스크에 패러티 정보를 넣어서 분산함. 그렇게 하므로써 패러티 디스크의 병목현상을 없애고 하나의 디스크가 문제가 생기더라도 다른 디스크의 패러티 정보를 이용하여 복구가능 / 현재 가장 널리 사용되는 raid level이다

